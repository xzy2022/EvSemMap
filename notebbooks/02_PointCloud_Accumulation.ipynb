{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8be7050-98cd-48bc-9788-707632a6a0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "成功导入 rellis_utils\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d # 建议安装 open3d 用于更好的点云显示，如果没有安装，后面有点云显示的 fallback 代码\n",
    "\n",
    "# ================= 路径设置与导入 =================\n",
    "# 将 Projection 目录加入路径\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"Projection\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "try:\n",
    "    from rellis_utils.lidar2img import load_from_bin, get_cam_mtx, get_mtx_from_yaml\n",
    "    print(\"成功导入 rellis_utils\")\n",
    "except ImportError as e:\n",
    "    print(f\"导入失败: {e}，请检查 project_root: {project_root}\")\n",
    "\n",
    "# ================= 步骤一核心函数封装 =================\n",
    "def project_and_filter(lidar_points, P, RT_os1_to_cam, dist_coeff, img_size):\n",
    "    h, w = img_size\n",
    "    xyz_h = np.hstack((lidar_points, np.ones((lidar_points.shape[0], 1))))\n",
    "    xyz_cam = (RT_os1_to_cam @ xyz_h.T).T[:, :3]\n",
    "    \n",
    "    # Z轴过滤 (前方且不过近)\n",
    "    mask_z = xyz_cam[:, 2] > 2.0 \n",
    "    xyz_cam = xyz_cam[mask_z]\n",
    "    lidar_points_filtered = lidar_points[mask_z]\n",
    "    \n",
    "    # 投影\n",
    "    rvec = np.zeros((3, 1)); tvec = np.zeros((3, 1))\n",
    "    img_points, _ = cv2.projectPoints(xyz_cam, rvec, tvec, P, dist_coeff)\n",
    "    img_points = img_points.squeeze()\n",
    "    \n",
    "    # 图像边界过滤\n",
    "    u, v = img_points[:, 0], img_points[:, 1]\n",
    "    mask_uv = (u >= 0) & (u < w) & (v >= 0) & (v < h)\n",
    "    return img_points[mask_uv], xyz_cam[mask_uv], lidar_points_filtered[mask_uv]\n",
    "\n",
    "def handle_occlusion(img_points, cam_points, img_size):\n",
    "    h, w = img_size\n",
    "    u = np.round(img_points[:, 0]).astype(int)\n",
    "    v = np.round(img_points[:, 1]).astype(int)\n",
    "    depth = cam_points[:, 2]\n",
    "    \n",
    "    # 扁平化索引用于去重\n",
    "    flat_indices = v * w + u\n",
    "    sort_idx = np.argsort(depth) # 按深度排序\n",
    "    _, unique_idx = np.unique(flat_indices[sort_idx], return_index=True)\n",
    "    return sort_idx[unique_idx] # 返回深度最小的点的原始索引\n",
    "\n",
    "def process_single_frame(lidar_file, prob_map_file, P, RT, dist_coeff, proj_shape, map_shape):\n",
    "    \"\"\"\n",
    "    输入: 单帧文件路径\n",
    "    输出: 剔除遮挡后的 3D 点 (LiDAR坐标系) 和 对应的概率向量\n",
    "    \"\"\"\n",
    "    points = load_from_bin(lidar_file)\n",
    "    prob_map = np.load(prob_map_file) \n",
    "    \n",
    "    # 1. 投影与视锥过滤\n",
    "    img_pts, cam_pts, raw_pts = project_and_filter(points, P, RT, dist_coeff, proj_shape)\n",
    "    \n",
    "    # 2. 遮挡剔除 (使用投影分辨率)\n",
    "    keep_idx = handle_occlusion(img_pts, cam_pts, proj_shape)\n",
    "    img_pts, raw_pts = img_pts[keep_idx], raw_pts[keep_idx]\n",
    "    \n",
    "    # 3. 采样概率 (映射到概率图分辨率)\n",
    "    scale_x, scale_y = map_shape[1] / proj_shape[1], map_shape[0] / proj_shape[0]\n",
    "    u_map = np.clip((img_pts[:, 0] * scale_x).astype(int), 0, map_shape[1]-1)\n",
    "    v_map = np.clip((img_pts[:, 1] * scale_y).astype(int), 0, map_shape[0]-1)\n",
    "    \n",
    "    point_probs = prob_map[:, v_map, u_map].T \n",
    "    return raw_pts, point_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec97ca9b-40d1-40f8-97f3-325d05813fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0204fd4b-d4cc-4ca0-89d2-85afd77fa77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标定加载完成.\n",
      " P shape: (3, 3)\n",
      " RT shape: (4, 4)\n",
      "成功加载位姿，共 2059 帧\n"
     ]
    }
   ],
   "source": [
    "# ================= 配置区域 (Updated for Step 2) =================\n",
    "# 1. 基础路径\n",
    "RELLIS_ROOT = '/home/xzy/datasets/Rellis-3D'\n",
    "INFERENCE_DIR = '/home/xzy/Downloads/convertedRellis/rellisv3_edl_train-4/01_inferenced_npy'\n",
    "SEQ_ID = '00004' \n",
    "\n",
    "# 2. [新增] 序列处理配置\n",
    "START_FRAME_IDX = 0    # 从第几帧开始\n",
    "NUM_FRAMES = 10        # 累积多少帧 (建议先用 5-10 帧测试)\n",
    "BASE_FRAME_IDX = 0     # 以哪一帧为原点 (通常等于 START_FRAME_IDX)\n",
    "\n",
    "# 3. [新增] 位姿文件路径\n",
    "# Rellis 的 poses.txt 通常在序列目录下\n",
    "POSES_FILE = os.path.join(RELLIS_ROOT, SEQ_ID, 'poses.txt')\n",
    "\n",
    "# 4. 畸变系数 (保持不变)\n",
    "dist_coeff = np.array([-0.134313,-0.025905,0.002181,0.00084,0]).reshape((5,1))\n",
    "\n",
    "# 5. 分辨率配置 (需要在循环外定义)\n",
    "PROJ_SHAPE = (1200, 1920) # 原始图像分辨率 (H, W)\n",
    "MAP_SHAPE = (600, 960)    # 推理结果分辨率 (H, W), 请根据实际 .npy 形状调整\n",
    "\n",
    "# ================= 标定参数加载 =================\n",
    "# 自动寻找配置文件\n",
    "cam_info_path = os.path.join(RELLIS_ROOT, 'Rellis_3D_cam_intrinsic', 'Rellis-3D', SEQ_ID, 'camera_info.txt')\n",
    "if not os.path.exists(cam_info_path): cam_info_path = os.path.join(RELLIS_ROOT, SEQ_ID, 'camera_info.txt')\n",
    "\n",
    "trans_path = os.path.join(RELLIS_ROOT, SEQ_ID, 'transforms.yaml')\n",
    "\n",
    "# 加载 P 和 RT\n",
    "P = get_cam_mtx(cam_info_path)\n",
    "RT_os1_to_cam = get_mtx_from_yaml(trans_path)\n",
    "\n",
    "print(f\"标定加载完成.\\n P shape: {P.shape}\\n RT shape: {RT_os1_to_cam.shape}\")\n",
    "\n",
    "# ================= [新增] 位姿加载函数 =================\n",
    "def load_poses(pose_file):\n",
    "    \"\"\"\n",
    "    读取 KITTI 格式的 poses.txt (N x 12)，返回 (N, 4, 4) 的变换矩阵列表\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pose_file):\n",
    "        raise FileNotFoundError(f\"位姿文件未找到: {pose_file}\")\n",
    "    \n",
    "    poses = []\n",
    "    with open(pose_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            # 将 12 个数转为 3x4 矩阵，最后补一行 [0,0,0,1]\n",
    "            vals = np.fromstring(line, sep=' ')\n",
    "            mat = vals.reshape(3, 4)\n",
    "            mat_4x4 = np.eye(4)\n",
    "            mat_4x4[:3, :] = mat\n",
    "            poses.append(mat_4x4)\n",
    "    return poses\n",
    "\n",
    "# 加载位姿\n",
    "all_poses = load_poses(POSES_FILE)\n",
    "print(f\"成功加载位姿，共 {len(all_poses)} 帧\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277447ab-0890-4596-8273-e1e01b09c007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882fdadf-c128-4ad1-adef-9a97dae568f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e117007-6b8b-4b11-8fd9-1845ed49bb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始拼接序列 00004, 帧 0 到 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 28.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "拼接完成!\n",
      "总点数: 58515\n",
      "概率矩阵形状: (58515, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================= 拼接主循环 =================\n",
    "\n",
    "acc_points_list = [] # 存储拼接后的几何点 (x, y, z)\n",
    "acc_probs_list = []  # 存储对应的概率向量\n",
    "\n",
    "# 获取基准帧的位姿逆矩阵 T_world_to_base\n",
    "T_world_curr = all_poses[BASE_FRAME_IDX]\n",
    "T_base_inv = np.linalg.inv(T_world_curr)\n",
    "\n",
    "print(f\"开始拼接序列 {SEQ_ID}, 帧 {START_FRAME_IDX} 到 {START_FRAME_IDX + NUM_FRAMES - 1}...\")\n",
    "\n",
    "for i in tqdm(range(START_FRAME_IDX, START_FRAME_IDX + NUM_FRAMES)):\n",
    "    frame_str = f\"{i:06d}\"\n",
    "    \n",
    "    # --- 1. 动态构建路径 (保持您的 glob 风格) ---\n",
    "    lidar_path = os.path.join(RELLIS_ROOT, SEQ_ID, 'os1_cloud_node_kitti_bin', f\"{frame_str}.bin\")\n",
    "    \n",
    "    # 查找 npy 文件 (处理时间戳后缀)\n",
    "    npy_pattern = os.path.join(INFERENCE_DIR, SEQ_ID, f\"frame{frame_str}-*.npy\")\n",
    "    npy_matches = glob.glob(npy_pattern)\n",
    "    \n",
    "    if not os.path.exists(lidar_path) or len(npy_matches) == 0:\n",
    "        print(f\"跳过帧 {frame_str}: 文件缺失\")\n",
    "        continue\n",
    "    \n",
    "    npy_path = npy_matches[0]\n",
    "    \n",
    "    # --- 2. 获取单帧数据 (调用 Step 1 函数) ---\n",
    "    # pts_local 是当前帧 LiDAR 坐标系下的点\n",
    "    pts_local, probs = process_single_frame(\n",
    "        lidar_path, npy_path, P, RT_os1_to_cam, dist_coeff, PROJ_SHAPE, MAP_SHAPE\n",
    "    )\n",
    "    \n",
    "    if len(pts_local) == 0:\n",
    "        continue\n",
    "        \n",
    "    # --- 3. 坐标变换 (Space Transformation) ---\n",
    "    # 公式: P_base = T_base_inv * T_curr * P_curr\n",
    "    \n",
    "    # 当前帧位姿 T_world_to_curr\n",
    "    T_curr = all_poses[i]\n",
    "    \n",
    "    # 计算相对位姿 T_curr_to_base\n",
    "    T_rel = T_base_inv @ T_curr\n",
    "    \n",
    "    # 齐次变换\n",
    "    pts_homo = np.hstack((pts_local, np.ones((pts_local.shape[0], 1)))) # (N, 4)\n",
    "    pts_aligned = (T_rel @ pts_homo.T).T # (N, 4)\n",
    "    pts_aligned = pts_aligned[:, :3]     # (N, 3)\n",
    "    \n",
    "    # --- 4. 收集数据 ---\n",
    "    acc_points_list.append(pts_aligned)\n",
    "    acc_probs_list.append(probs)\n",
    "\n",
    "# 合并所有帧\n",
    "if len(acc_points_list) > 0:\n",
    "    global_points = np.vstack(acc_points_list)\n",
    "    global_probs = np.vstack(acc_probs_list)\n",
    "    \n",
    "    # 获取每个点的最大概率类别用于着色\n",
    "    global_labels = np.argmax(global_probs, axis=1)\n",
    "    \n",
    "    print(f\"拼接完成!\")\n",
    "    print(f\"总点数: {global_points.shape[0]}\")\n",
    "    print(f\"概率矩阵形状: {global_probs.shape}\")\n",
    "else:\n",
    "    print(\"错误: 未收集到任何点云数据。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a7e1d3b-e3a9-4c96-9584-68fa1afbe870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rellis_colors(labels):\n",
    "    \"\"\"\n",
    "    输入: \n",
    "        labels: (N,) 的整数数组，代表 Rellis-3D 的原始类别 ID (0-34)\n",
    "    输出:\n",
    "        colors: (N, 3) 的 float 数组 (0.0-1.0)，用于 Open3D/Matplotlib 显示\n",
    "    \"\"\"\n",
    "    # 1. 建立 ID -> Group 的映射表 (Class ID to Color Category)\n",
    "    # 使用数组实现快速查找，大小设为 35 (最大ID 34 + 1)\n",
    "    id_to_group = np.zeros(35, dtype=int)\n",
    "    \n",
    "    # 填入您提供的表 1 数据\n",
    "    mapping_data = {\n",
    "        0:0, 1:6, 2:5, 3:7, 4:8, 5:3, 6:2, 7:1, 8:3, 9:3, \n",
    "        10:4, 11:5, 12:3, 13:6, 14:5, 15:6, 16:3, 17:3, 18:0, \n",
    "        19:8, 20:3, 21:0, 22:3, 23:4, 24:3, 27:0, 31:2, 33:6, 34:0\n",
    "    }\n",
    "    \n",
    "    for cls_id, grp_id in mapping_data.items():\n",
    "        if cls_id < 35:\n",
    "            id_to_group[cls_id] = grp_id\n",
    "\n",
    "    # 2. 建立 Group -> RGB 的映射表 (Color Category to RGB)\n",
    "    # 填入您提供的表 2 数据 (归一化到 0-1)\n",
    "    group_colors = np.array([\n",
    "        [0, 0, 0],       # 0: void\n",
    "        [196, 255, 255], # 1: sky\n",
    "        [0, 0, 255],     # 2: water\n",
    "        [204, 153, 255], # 3: object\n",
    "        [255, 255, 0],   # 4: paved\n",
    "        [255, 153, 204], # 5: unpaved\n",
    "        [153, 76, 0],    # 6: brown (dirt/mulch)\n",
    "        [111, 255, 74],  # 7: green (grass)\n",
    "        [0, 102, 0]      # 8: vegetation (tree/bush)\n",
    "    ]) / 255.0\n",
    "\n",
    "    # 3. 执行映射\n",
    "    # 第一步：Label -> Group\n",
    "    # 处理超出范围的标签（为了安全，映射为 0）\n",
    "    safe_labels = labels.copy()\n",
    "    safe_labels[safe_labels >= 35] = 0\n",
    "    groups = id_to_group[safe_labels]\n",
    "    \n",
    "    # 第二步：Group -> Color\n",
    "    colors = group_colors[groups]\n",
    "    \n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb901a-dcc6-4e39-aac3-5c944f2690f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "def visualize_with_coordinates(points, labels, T_world_curr_base):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "        points: (N, 3) 点云数据 (已变换到 Base Frame)\n",
    "        labels: (N,) 原始类别标签\n",
    "        T_world_curr_base: (4, 4) 基准帧在世界坐标系下的位姿 (即 all_poses[BASE_FRAME_IDX])\n",
    "    \"\"\"\n",
    "    # --- 1. 创建点云对象 ---\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    # 应用自定义颜色映射\n",
    "    colors = get_rellis_colors(labels)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "    # --- 2. 创建坐标轴 ---\n",
    "    \n",
    "    # A. 基准帧坐标轴 (Base Frame Axis)\n",
    "    # 因为点云已经是 Base Frame 下的，所以 Base Frame 就在原点 (0,0,0)\n",
    "    # 我们用一个小一点的坐标轴表示，代表\"车的起始位置\"\n",
    "    axis_base = o3d.geometry.TriangleMesh.create_coordinate_frame(size=2.0, origin=[0, 0, 0])\n",
    "    \n",
    "    # B. 世界坐标轴 (World Frame Axis)\n",
    "    # 我们需要求出 World Frame 在 Base Frame 视角下的位置。\n",
    "    # 已知: P_world = T_world_curr_base * P_base\n",
    "    # 所以: P_base  = inv(T_world_curr_base) * P_world\n",
    "    # 世界原点 (World Origin) 在 World Frame 中是 Identity。\n",
    "    # 在 Base Frame 中，它就是 inv(T_world_curr_base)。\n",
    "    T_base_to_world_view = np.linalg.inv(T_world_curr_base)\n",
    "    \n",
    "    axis_world = o3d.geometry.TriangleMesh.create_coordinate_frame(size=5.0) #以此区分，设大一点\n",
    "    axis_world.transform(T_base_to_world_view)\n",
    "    \n",
    "    # --- 3. 渲染 ---\n",
    "    print(\"可视化说明:\")\n",
    "    print(\"1. 点云颜色: 已应用 Rellis-3D 官方/简化配色\")\n",
    "    print(\"2. 小坐标轴 (Size 2.0): 起始帧 (Base Frame) 位置 (你在这里)\")\n",
    "    print(\"3. 大坐标轴 (Size 5.0): 世界原点 (World Frame) 位置 (poses.txt 的 0,0,0)\")\n",
    "    \n",
    "    o3d.visualization.draw_geometries([pcd, axis_base, axis_world],\n",
    "                                      zoom=0.3412,\n",
    "                                      front=[0.4257, -0.2125, -0.8795],\n",
    "                                      lookat=[2.6172, 2.0475, 1.532],\n",
    "                                      up=[-0.0694, -0.9768, 0.2024],\n",
    "                                      window_name=\"Rellis-3D Accumulation\")\n",
    "\n",
    "# ================= 调用示例 =================\n",
    "# 请确保此时 global_points 和 global_labels 已经由上一段代码生成\n",
    "# all_poses[BASE_FRAME_IDX] 就是基准帧的位姿矩阵\n",
    "\n",
    "if 'global_points' in locals():\n",
    "    visualize_with_coordinates(global_points, global_labels, all_poses[BASE_FRAME_IDX])\n",
    "else:\n",
    "    print(\"请先运行点云拼接代码块生成 global_points 数据。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b80476-284f-4fb2-9cb4-30a52944d498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
