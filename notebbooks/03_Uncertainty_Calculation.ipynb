{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167ba564-909b-4f66-bd35-3eca5c420d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused Mass: [0.61748456 0.02989925 0.0601235 ]\n",
      "Fused Unc: [0.29249269]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def alpha_to_mass(alpha):\n",
    "    \"\"\"\n",
    "    将 Dirichlet 参数 alpha 转换为 DS Mass 和 Uncertainty\n",
    "    Input: alpha (..., K)\n",
    "    Output: mass (..., K), uncertainty (..., 1)\n",
    "    \"\"\"\n",
    "    S = np.sum(alpha, axis=-1, keepdims=True) # S = sum(alpha)\n",
    "    K = alpha.shape[-1]\n",
    "    \n",
    "    # Mass k = (alpha_k - 1) / S\n",
    "    mass = (alpha - 1.0) / S\n",
    "    \n",
    "    # Uncertainty = K / S\n",
    "    uncertainty = K / S\n",
    "    \n",
    "    # 裁剪防止数值误差导致负数 (理论上 alpha >= 1)\n",
    "    mass = np.maximum(mass, 0.0)\n",
    "    \n",
    "    return mass, uncertainty\n",
    "\n",
    "def dempster_fusion(m1, m2, u1, u2):\n",
    "    \"\"\"\n",
    "    DS 组合规则融合两个 Mass 分布\n",
    "    m1, m2: (K,) 或 (N, K) 的 Mass 向量\n",
    "    u1, u2: (1,) 或 (N, 1) 的 Uncertainty 标量\n",
    "    \"\"\"\n",
    "    # 1. 计算冲突因子 C (Conflict)\n",
    "    # C = sum_{i!=j} m1[i] * m2[j]\n",
    "    # 可以通过外积计算所有对的乘积，然后减去对角线(i==j)的部分\n",
    "    \n",
    "    # 为了支持批量计算 (N, K)，我们使用 einsum 或者 广播\n",
    "    # 这里展示单点逻辑的向量化版本\n",
    "    \n",
    "    # 计算所有两两乘积矩阵 (N, K, K)\n",
    "    # product_matrix[n, i, j] = m1[n, i] * m2[n, j]\n",
    "    product_matrix = np.einsum('...i,...j->...ij', m1, m2)\n",
    "    \n",
    "    # 对角线部分 (i==j):用于共识\n",
    "    diagonal = np.diagonal(product_matrix, axis1=-2, axis2=-1) # (..., K)\n",
    "    consensus = diagonal\n",
    "    \n",
    "    # 冲突 C = 所有元素和 - 对角线元素和\n",
    "    C = np.sum(product_matrix, axis=(-2, -1)) - np.sum(consensus, axis=-1)\n",
    "    \n",
    "    # 2. 归一化因子\n",
    "    norm_factor = 1.0 - C\n",
    "    # 防止除以0\n",
    "    norm_factor = np.maximum(norm_factor, 1e-8)\n",
    "    \n",
    "    # 3. 融合公式\n",
    "    # m_new[i] = (m1[i]*m2[i] + m1[i]*u2 + m2[i]*u1) / (1-C)\n",
    "    \n",
    "    term1 = consensus           # m1[i] * m2[i]\n",
    "    term2 = m1 * u2             # m1[i] * u2 (广播)\n",
    "    term3 = m2 * u1             # m2[i] * u1 (广播)\n",
    "    \n",
    "    m_new = (term1 + term2 + term3) / norm_factor[..., None]\n",
    "    \n",
    "    # 计算新的不确定性 (理论上 u_new = 1 - sum(m_new))\n",
    "    # 或者用公式 u_new = (u1 * u2) / (1-C)\n",
    "    u_new = (u1 * u2) / norm_factor[..., None]\n",
    "    \n",
    "    return m_new, u_new\n",
    "\n",
    "# === 使用示例 ===\n",
    "# 假设从 .npy 读取了 alpha\n",
    "alpha_obs = np.array([2.0, 1.2, 1.5]) # 假设3类\n",
    "current_map_mass = np.array([0.0, 0.0, 0.0]) # 初始全0\n",
    "current_map_unc = 1.0\n",
    "\n",
    "# 1. 转换\n",
    "obs_mass, obs_unc = alpha_to_mass(alpha_obs)\n",
    "\n",
    "# 2. 融合\n",
    "# 如果是第一次 (num=0)，直接赋值\n",
    "current_map_mass = obs_mass\n",
    "current_map_unc = obs_unc\n",
    "\n",
    "# 如果是第二次观测\n",
    "alpha_obs_2 = np.array([5.0, 1.1, 1.1])\n",
    "obs_mass_2, obs_unc_2 = alpha_to_mass(alpha_obs_2)\n",
    "\n",
    "fused_mass, fused_unc = dempster_fusion(current_map_mass, obs_mass_2, current_map_unc, obs_unc_2)\n",
    "\n",
    "print(\"Fused Mass:\", fused_mass)\n",
    "print(\"Fused Unc:\", fused_unc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8b9f59-d1ef-4ab5-bec9-24b49cc841f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. 基础配置\n",
    "VOXEL_RESOLUTION = 0.2  # 分辨率，单位：米 (原项目典型值)\n",
    "NUM_CLASSES = 9         # 类别数\n",
    "\n",
    "# 2. 地图容器 (稀疏体素网格)\n",
    "# Key: (x_idx, y_idx, z_idx)\n",
    "# Value: { 'mass': np.array, 'uncertainty': float }\n",
    "voxel_map = {} \n",
    "\n",
    "def get_voxel_index(point, resolution):\n",
    "    \"\"\"将物理坐标转换为体素索引\"\"\"\n",
    "    return tuple(np.floor(point / resolution).astype(int))\n",
    "\n",
    "def update_voxel_map(voxel_map, points, point_alphas, resolution):\n",
    "    \"\"\"\n",
    "    更新体素地图的主函数\n",
    "    points: (N, 3) 点云坐标\n",
    "    point_alphas: (N, K) 每个点的 Dirichlet 参数 (from .npy)\n",
    "    \"\"\"\n",
    "    # 预先计算所有点的体素索引 (向量化加速)\n",
    "    voxel_indices = np.floor(points / resolution).astype(int)\n",
    "    \n",
    "    # 遍历每个点进行融合\n",
    "    # 注意：为了效率，实际工程中通常会先对 indices 进行 argsort 或 unique，\n",
    "    # 将属于同一个体素的点先在这一帧内合并，再与全局地图融合。\n",
    "    # 这里为了演示逻辑，使用简单的逐点循环。\n",
    "    \n",
    "    for i in range(len(points)):\n",
    "        idx = tuple(voxel_indices[i])\n",
    "        \n",
    "        # 1. 获取当前观测的 Mass 和 Uncertainty\n",
    "        # (假设您已经实现了上一步的 alpha_to_mass 函数)\n",
    "        obs_alpha = point_alphas[i]\n",
    "        obs_mass, obs_unc = alpha_to_mass(obs_alpha) # 需定义此函数\n",
    "        \n",
    "        if idx not in voxel_map:\n",
    "            # --- 初始化新体素 ---\n",
    "            voxel_map[idx] = {\n",
    "                'mass': obs_mass,\n",
    "                'uncertainty': obs_unc,\n",
    "                'count': 1\n",
    "            }\n",
    "        else:\n",
    "            # --- 融合旧体素 ---\n",
    "            curr_voxel = voxel_map[idx]\n",
    "            old_mass = curr_voxel['mass']\n",
    "            old_unc = curr_voxel['uncertainty']\n",
    "            \n",
    "            # 调用 Dempster 组合规则 (需定义此函数)\n",
    "            new_mass, new_unc = dempster_fusion(old_mass, obs_mass, old_unc, obs_unc)\n",
    "            \n",
    "            # 更新状态\n",
    "            curr_voxel['mass'] = new_mass\n",
    "            curr_voxel['uncertainty'] = new_unc\n",
    "            curr_voxel['count'] += 1\n",
    "\n",
    "    return voxel_map\n",
    "\n",
    "# 3. 将地图转换为点云用于可视化\n",
    "def map_to_pointcloud(voxel_map, resolution):\n",
    "    points = []\n",
    "    colors = [] # 或 semantics\n",
    "    uncertainties = []\n",
    "    \n",
    "    for idx, data in voxel_map.items():\n",
    "        # 恢复物理坐标 (取体素中心)\n",
    "        center_point = (np.array(idx) * resolution) + (resolution / 2.0)\n",
    "        \n",
    "        # 获取最大概率类别\n",
    "        mass = data['mass']\n",
    "        label = np.argmax(mass)\n",
    "        \n",
    "        points.append(center_point)\n",
    "        colors.append(label) # 这里存 label，后续用 get_rellis_colors 转颜色\n",
    "        uncertainties.append(data['uncertainty'])\n",
    "        \n",
    "    return np.array(points), np.array(colors), np.array(uncertainties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c34fd7-fac0-4f66-b1cf-4b1cc212f66f",
   "metadata": {},
   "source": [
    "## 1: 导入与基础配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8f0290-797e-42ec-a219-23a259ecb8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "成功导入 rellis_utils\n",
      "标定加载完毕. P: (3, 3), Poses: 2059\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================= 1. 路径设置 (复用 Step 2) =================\n",
    "# 请确保 project_root 指向包含 rellis_utils 的目录\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"Projection\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "try:\n",
    "    from rellis_utils.lidar2img import load_from_bin, get_cam_mtx, get_mtx_from_yaml\n",
    "    print(\"成功导入 rellis_utils\")\n",
    "except ImportError as e:\n",
    "    print(f\"导入失败: {e}\")\n",
    "\n",
    "# ================= 2. 数据集配置 =================\n",
    "RELLIS_ROOT = '/home/xzy/datasets/Rellis-3D'\n",
    "INFERENCE_DIR = '/home/xzy/Downloads/convertedRellis/rellisv3_edl_train-4/01_inferenced_npy'\n",
    "SEQ_ID = '00004'\n",
    "\n",
    "# 处理帧数范围\n",
    "START_FRAME_IDX = 0\n",
    "NUM_FRAMES = 10        # 建议跑 100-200 帧以观察融合效果\n",
    "VOXEL_SIZE = 0.2        # 体素分辨率 (单位: 米)，越小越精细但内存消耗越大\n",
    "\n",
    "# 图像与投影参数\n",
    "PROJ_SHAPE = (1200, 1920) \n",
    "MAP_SHAPE = (600, 960)    \n",
    "dist_coeff = np.array([-0.134313,-0.025905,0.002181,0.00084,0]).reshape((5,1))\n",
    "\n",
    "# ================= 3. 加载标定与位姿 =================\n",
    "# 相机参数\n",
    "cam_info_path = os.path.join(RELLIS_ROOT, 'Rellis_3D_cam_intrinsic', 'Rellis-3D', SEQ_ID, 'camera_info.txt')\n",
    "if not os.path.exists(cam_info_path): cam_info_path = os.path.join(RELLIS_ROOT, SEQ_ID, 'camera_info.txt')\n",
    "trans_path = os.path.join(RELLIS_ROOT, SEQ_ID, 'transforms.yaml')\n",
    "poses_file = os.path.join(RELLIS_ROOT, SEQ_ID, 'poses.txt')\n",
    "\n",
    "P = get_cam_mtx(cam_info_path)\n",
    "RT_os1_to_cam = get_mtx_from_yaml(trans_path)\n",
    "\n",
    "def load_poses(pose_file):\n",
    "    poses = []\n",
    "    with open(pose_file, 'r') as f:\n",
    "        for line in f:\n",
    "            mat = np.eye(4)\n",
    "            mat[:3, :] = np.fromstring(line, sep=' ').reshape(3, 4)\n",
    "            poses.append(mat)\n",
    "    return poses\n",
    "\n",
    "all_poses = load_poses(poses_file)\n",
    "print(f\"标定加载完毕. P: {P.shape}, Poses: {len(all_poses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6613c00-21ed-465e-a279-20b4f2569db5",
   "metadata": {},
   "source": [
    "## 2. 核心数学工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d4e9c3-fc1c-4d1f-b368-3efc3620ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= 证据理论 (Evidential Theory) 核心函数 =================\n",
    "\n",
    "def alpha_to_mass(alpha):\n",
    "    \"\"\"\n",
    "    将 Dirichlet 参数 alpha 转换为 DS Mass 和 Uncertainty\n",
    "    Input: alpha (..., K)\n",
    "    Output: mass (..., K), uncertainty (..., 1)\n",
    "    \"\"\"\n",
    "    # 确保 alpha >= 1.0 (防止数值下溢)\n",
    "    alpha = np.maximum(alpha, 1.0001)\n",
    "    \n",
    "    S = np.sum(alpha, axis=-1, keepdims=True) # S = sum(alpha)\n",
    "    K = alpha.shape[-1]\n",
    "    \n",
    "    # Belief/Mass k = (alpha_k - 1) / S\n",
    "    mass = (alpha - 1.0) / S\n",
    "    \n",
    "    # Uncertainty = K / S\n",
    "    uncertainty = K / S\n",
    "    \n",
    "    return mass, uncertainty\n",
    "\n",
    "def dempster_fusion_numpy(m1, m2, u1, u2):\n",
    "    \"\"\"\n",
    "    DS 组合规则 (Vectorized Numpy Version)\n",
    "    融合两个 Mass 分布 m1 (old), m2 (new observation)\n",
    "    \"\"\"\n",
    "    # 维度检查与广播处理\n",
    "    if m1.ndim == 1: m1 = m1[None, :]\n",
    "    if m2.ndim == 1: m2 = m2[None, :]\n",
    "    if np.isscalar(u1): u1 = np.array([u1])\n",
    "    if np.isscalar(u2): u2 = np.array([u2])\n",
    "    \n",
    "    # 1. 计算冲突因子 C (Conflict)\n",
    "    # 使用 einsum 计算外积矩阵: product[n, i, j] = m1[n, i] * m2[n, j]\n",
    "    product_matrix = np.einsum('...i,...j->...ij', m1, m2)\n",
    "    \n",
    "    # 对角线元素 (i==j) 代表两个证据支持同一类\n",
    "    consensus = np.diagonal(product_matrix, axis1=-2, axis2=-1)\n",
    "    \n",
    "    # 冲突 C = 所有元素和 - 对角线元素和\n",
    "    # sum_prod = np.sum(product_matrix, axis=(-2, -1)) # 理论上等于 sum(m1)*sum(m2)\n",
    "    # 简化计算：如果 m+u=1，则 sum(m) 可能会小于1。\n",
    "    # 标准 DS 公式中分母是 1 - K，这里 K 是冲突 mass。\n",
    "    \n",
    "    sum_all = np.sum(product_matrix, axis=(-2, -1))\n",
    "    sum_diag = np.sum(consensus, axis=-1)\n",
    "    C = sum_all - sum_diag\n",
    "    \n",
    "    # 归一化因子 1 / (1-C)\n",
    "    norm_factor = 1.0 - C\n",
    "    norm_factor = np.maximum(norm_factor, 1e-7) # 避免除零\n",
    "    \n",
    "    # 2. 融合 Mass\n",
    "    # m_new[i] = (m1[i]*m2[i] + m1[i]*u2 + m2[i]*u1) / (1-C)\n",
    "    term1 = consensus           # m1[i] * m2[i]\n",
    "    term2 = m1 * u2[..., None]  # m1[i] * u2\n",
    "    term3 = m2 * u1[..., None]  # m2[i] * u1\n",
    "    \n",
    "    m_new = (term1 + term2 + term3) / norm_factor[..., None]\n",
    "    \n",
    "    # 3. 融合 Uncertainty\n",
    "    # u_new = (u1 * u2) / (1-C)\n",
    "    u_new = (u1 * u2) / norm_factor\n",
    "    \n",
    "    return m_new.squeeze(), u_new.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735acedc-f06b-4581-8e30-2cee5405e238",
   "metadata": {},
   "source": [
    "## 3. Voxel Map 类定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3618c1c6-c781-4aa6-8dcc-86bd0f130e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel Map 类定义完成。\n"
     ]
    }
   ],
   "source": [
    "class EvidentialVoxelMap:\n",
    "    def __init__(self, resolution=0.2, num_classes=9):\n",
    "        self.resolution = resolution\n",
    "        self.num_classes = num_classes\n",
    "        # 稀疏地图: Key=(x,y,z), Value={'mass': np.array, 'unc': float, 'count': int}\n",
    "        self.voxels = {} \n",
    "\n",
    "    def update(self, points, alphas):\n",
    "        \"\"\"\n",
    "        更新地图状态\n",
    "        points: (N, 3) 世界坐标系下的点\n",
    "        alphas: (N, K) 对应的 Dirichlet 参数\n",
    "        \"\"\"\n",
    "        # 1. 转换观测值为 Mass/Uncertainty\n",
    "        obs_masses, obs_uncs = alpha_to_mass(alphas)\n",
    "        \n",
    "        # 2. 计算体素索引\n",
    "        voxel_indices = np.floor(points / self.resolution).astype(int)\n",
    "        \n",
    "        # 3. 逐点融合 (这里使用简单的 Python 循环，后续可用 C++ 绑定或 Numba 优化)\n",
    "        # 为了加速，我们先在当前帧内部进行聚合（处理同一帧落入同一体素的点）\n",
    "        \n",
    "        # 构建当前帧的临时字典: idx -> list of indices\n",
    "        unique_indices, inv_inds = np.unique(voxel_indices, axis=0, return_inverse=True)\n",
    "        \n",
    "        # 遍历当前帧涉及的每一个体素\n",
    "        for i, idx_arr in enumerate(unique_indices):\n",
    "            idx_tuple = tuple(idx_arr)\n",
    "            \n",
    "            # 找到当前帧所有属于该体素的点\n",
    "            mask = (inv_inds == i)\n",
    "            \n",
    "            # === 策略 A: 帧内取平均 (简单且有效) ===\n",
    "            # 同一帧内打到同一个体素的点，通常视为一次观测，取 alpha 的均值作为本次观测\n",
    "            # (也可以取 Max，或者视为多次观测连续融合)\n",
    "            avg_mass = np.mean(obs_masses[mask], axis=0)\n",
    "            avg_unc = np.mean(obs_uncs[mask])\n",
    "            \n",
    "            if idx_tuple not in self.voxels:\n",
    "                # 初始化\n",
    "                self.voxels[idx_tuple] = {\n",
    "                    'mass': avg_mass,\n",
    "                    'uncertainty': avg_unc,\n",
    "                    'count': 1\n",
    "                }\n",
    "            else:\n",
    "                # 融合 (Temporal Fusion)\n",
    "                old_data = self.voxels[idx_tuple]\n",
    "                \n",
    "                new_m, new_u = dempster_fusion_numpy(\n",
    "                    old_data['mass'], avg_mass, \n",
    "                    old_data['uncertainty'], avg_unc\n",
    "                )\n",
    "                \n",
    "                # 更新状态\n",
    "                self.voxels[idx_tuple]['mass'] = new_m\n",
    "                self.voxels[idx_tuple]['uncertainty'] = new_u\n",
    "                self.voxels[idx_tuple]['count'] += 1\n",
    "\n",
    "    def to_pointcloud(self):\n",
    "        \"\"\"将体素地图导出为 numpy 数组用于可视化\"\"\"\n",
    "        if not self.voxels:\n",
    "            return None, None, None\n",
    "            \n",
    "        pts = []\n",
    "        labels = []\n",
    "        uncs = []\n",
    "        \n",
    "        for idx, data in self.voxels.items():\n",
    "            # 恢复中心坐标\n",
    "            pt = (np.array(idx) * self.resolution) + (self.resolution / 2.0)\n",
    "            pts.append(pt)\n",
    "            \n",
    "            # 获取最大概率类别\n",
    "            label = np.argmax(data['mass'])\n",
    "            labels.append(label)\n",
    "            \n",
    "            # 获取不确定性\n",
    "            uncs.append(data['uncertainty'])\n",
    "            \n",
    "        return np.array(pts), np.array(labels), np.array(uncs)\n",
    "\n",
    "    def prune(self, min_count=2):\n",
    "        \"\"\"(可选) 清除只观测到一两次的噪声体素\"\"\"\n",
    "        keys_to_remove = [k for k, v in self.voxels.items() if v['count'] < min_count]\n",
    "        for k in keys_to_remove:\n",
    "            del self.voxels[k]\n",
    "        print(f\"已修剪 {len(keys_to_remove)} 个噪声体素\")\n",
    "\n",
    "print(\"Voxel Map 类定义完成。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf797ff4-2c10-4498-8a6b-f8633c501e86",
   "metadata": {},
   "source": [
    "## 4. 主循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a272e8d-7d92-4ccf-8e6e-15c35b7e7afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始 Evidential Mapping (Frames 0 - 200)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▊                                                                                  | 9/200 [00:02<00:47,  4.06it/s]/tmp/ipykernel_11247/2635019481.py:60: RuntimeWarning: overflow encountered in divide\n",
      "  m_new = (term1 + term2 + term3) / norm_factor[..., None]\n",
      "  5%|████▎                                                                                | 10/200 [00:02<00:47,  4.02it/s]/tmp/ipykernel_11247/2635019481.py:48: RuntimeWarning: invalid value encountered in subtract\n",
      "  C = sum_all - sum_diag\n",
      " 74%|█████████████████████████████████████████████████████████████▋                      | 147/200 [00:36<00:13,  3.91it/s]/tmp/ipykernel_11247/2635019481.py:64: RuntimeWarning: overflow encountered in divide\n",
      "  u_new = (u1 * u2) / norm_factor\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:50<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已修剪 6693 个噪声体素\n",
      "建图完成! 总体素数量: 17184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================= 辅助投影函数 (复用 Step 2) =================\n",
    "def project_and_get_data(lidar_file, npy_file, P, RT, img_size, map_shape):\n",
    "    # 加载数据\n",
    "    points = load_from_bin(lidar_file)\n",
    "    prob_map = np.load(npy_file) # 这是 alpha map (H_map, W_map, K)\n",
    "    \n",
    "    # 投影\n",
    "    h, w = img_size\n",
    "    xyz_h = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    xyz_cam = (RT @ xyz_h.T).T[:, :3]\n",
    "    \n",
    "    # Z轴过滤\n",
    "    mask_z = xyz_cam[:, 2] > 3.0 \n",
    "    xyz_cam = xyz_cam[mask_z]\n",
    "    points = points[mask_z]\n",
    "    \n",
    "    # cv2 投影\n",
    "    img_points, _ = cv2.projectPoints(xyz_cam, np.zeros(3), np.zeros(3), P, dist_coeff)\n",
    "    img_points = img_points.squeeze()\n",
    "    \n",
    "    # 图像范围过滤\n",
    "    u, v = img_points[:, 0], img_points[:, 1]\n",
    "    mask_uv = (u >= 0) & (u < w) & (v >= 0) & (v < h)\n",
    "    \n",
    "    final_u = u[mask_uv]\n",
    "    final_v = v[mask_uv]\n",
    "    final_points = points[mask_uv] # Local LiDAR Frame\n",
    "    \n",
    "    # 采样 .npy (Alpha)\n",
    "    # 注意 map_shape 和 img_shape 的比例\n",
    "    scale_x = map_shape[1] / w\n",
    "    scale_y = map_shape[0] / h\n",
    "    \n",
    "    u_map = np.clip((final_u * scale_x).astype(int), 0, map_shape[1]-1)\n",
    "    v_map = np.clip((final_v * scale_y).astype(int), 0, map_shape[0]-1)\n",
    "    \n",
    "    # 获取每个点的 alpha 向量 (N, K)\n",
    "    # 注意 prob_map 形状通常是 (H, W, K) 或 (K, H, W)，请根据实际情况调整 transpose\n",
    "    # 假设 prob_map 是 (K, H, W)，如 Step 2 所述\n",
    "    if prob_map.shape[0] == 9: # Channels first\n",
    "        point_alphas = prob_map[:, v_map, u_map].T \n",
    "    else: # Channels last\n",
    "        point_alphas = prob_map[v_map, u_map, :]\n",
    "        \n",
    "    return final_points, point_alphas\n",
    "\n",
    "# ================= 主执行流程 =================\n",
    "\n",
    "# 1. 初始化地图\n",
    "global_map = EvidentialVoxelMap(resolution=VOXEL_SIZE, num_classes=9)\n",
    "\n",
    "print(f\"开始 Evidential Mapping (Frames {START_FRAME_IDX} - {START_FRAME_IDX + NUM_FRAMES})...\")\n",
    "\n",
    "for i in tqdm(range(START_FRAME_IDX, START_FRAME_IDX + NUM_FRAMES)):\n",
    "    frame_str = f\"{i:06d}\"\n",
    "    \n",
    "    # 构建路径\n",
    "    lidar_path = os.path.join(RELLIS_ROOT, SEQ_ID, 'os1_cloud_node_kitti_bin', f\"{frame_str}.bin\")\n",
    "    npy_pattern = os.path.join(INFERENCE_DIR, SEQ_ID, f\"frame{frame_str}-*.npy\")\n",
    "    npy_matches = glob.glob(npy_pattern)\n",
    "    \n",
    "    if not os.path.exists(lidar_path) or not npy_matches:\n",
    "        continue\n",
    "        \n",
    "    # 1. 获取单帧数据 (Local Frame)\n",
    "    pts_local, alphas = project_and_get_data(\n",
    "        lidar_path, npy_matches[0], P, RT_os1_to_cam, PROJ_SHAPE, MAP_SHAPE\n",
    "    )\n",
    "    \n",
    "    if len(pts_local) == 0: continue\n",
    "    \n",
    "    # 2. 转到世界坐标系 (World Frame)\n",
    "    T_curr = all_poses[i]\n",
    "    pts_homo = np.hstack((pts_local, np.ones((pts_local.shape[0], 1))))\n",
    "    pts_world = (T_curr @ pts_homo.T).T[:, :3]\n",
    "    \n",
    "    # 3. 更新体素地图\n",
    "    global_map.update(pts_world, alphas)\n",
    "\n",
    "# (可选) 修剪噪声\n",
    "global_map.prune(min_count=2)\n",
    "\n",
    "print(f\"建图完成! 总体素数量: {len(global_map.voxels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d25ca-0b4b-4774-af71-c68bfd2c2a47",
   "metadata": {},
   "source": [
    "## 5. 可视化 (不确定性与语义)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f41a87bf-aa60-475e-92a8-27fbaf429e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_rellis_colors(labels, mode='auto', verbose=True):\n",
    "    \"\"\"\n",
    "    获取 Rellis-3D 的颜色映射，支持原始标签(Raw)和归类标签(Group)。\n",
    "    \n",
    "    参数:\n",
    "        labels: (N,) 的整数数组/列表\n",
    "        mode: \n",
    "            'auto': 自动判断。如果 max(label) > 8 则认为是 'raw'，否则认为是 'group'。\n",
    "            'raw':  强制认为是原始 ID (0-34)。\n",
    "            'group': 强制认为是归类 ID (0-8)。\n",
    "        verbose: 是否打印详细的映射信息 (True/False)。\n",
    "        \n",
    "    输出:\n",
    "        colors: (N, 3) 的 float 数组 (0.0-1.0)\n",
    "    \"\"\"\n",
    "    labels = np.array(labels, dtype=int)\n",
    "    if labels.size == 0:\n",
    "        return np.zeros((0, 3))\n",
    "\n",
    "    # ================= Data Definition =================\n",
    "    # 1. Raw ID (0-34) -> Group ID (0-8)\n",
    "    # 索引为 Raw ID，值为 Group ID\n",
    "    raw_to_group_map = np.zeros(35, dtype=int)\n",
    "    mapping_data = {\n",
    "        0:0, 1:6, 2:5, 3:7, 4:8, 5:3, 6:2, 7:1, 8:3, 9:3, \n",
    "        10:4, 11:5, 12:3, 13:6, 14:5, 15:6, 16:3, 17:3, 18:0, \n",
    "        19:8, 20:3, 21:0, 22:3, 23:4, 24:3, 27:0, 31:2, 33:6, 34:0\n",
    "    }\n",
    "    for k, v in mapping_data.items():\n",
    "        if k < 35: raw_to_group_map[k] = v\n",
    "\n",
    "    # 2. Group ID (0-8) -> RGB (0-255)\n",
    "    group_rgb_dict = {\n",
    "        0: [0, 0, 0],       # void\n",
    "        1: [196, 255, 255], # sky\n",
    "        2: [0, 0, 255],     # water\n",
    "        3: [204, 153, 255], # object (pole, barrier, etc)\n",
    "        4: [255, 255, 0],   # paved (asphalt, concrete)\n",
    "        5: [255, 153, 204], # unpaved (mud, rubble)\n",
    "        6: [153, 76, 0],    # brown (dirt, mulch)\n",
    "        7: [111, 255, 74],  # green (grass)\n",
    "        8: [0, 102, 0]      # vegetation (tree, bush)\n",
    "    }\n",
    "    \n",
    "    # 3. Group ID -> Name (for logging)\n",
    "    group_names = {\n",
    "        0: \"Void\", 1: \"Sky\", 2: \"Water\", 3: \"Object\", 4: \"Paved\", \n",
    "        5: \"Unpaved\", 6: \"Brown(Dirt)\", 7: \"Green(Grass)\", 8: \"Vegetation\"\n",
    "    }\n",
    "\n",
    "    # ================= Mode Selection =================\n",
    "    max_val = np.max(labels)\n",
    "    \n",
    "    if mode == 'auto':\n",
    "        # 启发式判断：如果存在大于8的标签，一定是Raw；\n",
    "        # 如果全都在0-8之间，优先假设是Group (因为通常可视化时如果是Raw，很难完全避开>8的ID)\n",
    "        if max_val > 8:\n",
    "            current_mode = 'raw'\n",
    "        else:\n",
    "            current_mode = 'group'\n",
    "    else:\n",
    "        current_mode = mode\n",
    "\n",
    "    # ================= Mapping Execution =================\n",
    "    \n",
    "    # 最终用于查颜色的索引 (Group IDs)\n",
    "    target_groups = None \n",
    "\n",
    "    if current_mode == 'raw':\n",
    "        # 越界处理：超过34的全部设为0 (Void)\n",
    "        safe_labels = labels.copy()\n",
    "        safe_labels[safe_labels >= 35] = 0\n",
    "        target_groups = raw_to_group_map[safe_labels]\n",
    "    else: # mode == 'group'\n",
    "        # 越界处理：超过8的全部设为0 (Void)\n",
    "        target_groups = labels.copy()\n",
    "        target_groups[target_groups > 8] = 0\n",
    "    \n",
    "    # 映射颜色\n",
    "    # 先构建一个 (9, 3) 的颜色查找表数组\n",
    "    color_lookup = np.zeros((9, 3))\n",
    "    for i in range(9):\n",
    "        color_lookup[i] = group_rgb_dict[i]\n",
    "    \n",
    "    # 归一化到 0-1\n",
    "    color_lookup_norm = color_lookup / 255.0\n",
    "    \n",
    "    # 获取最终颜色\n",
    "    colors = color_lookup_norm[target_groups]\n",
    "\n",
    "    # ================= INFO Logging =================\n",
    "    if verbose:\n",
    "        unique_input = np.unique(labels)\n",
    "        unique_groups = np.unique(target_groups)\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "        print(f\"[Rellis Colors] 检测模式: {mode} -> 实际执行: {current_mode.upper()}\")\n",
    "        print(f\"[Rellis Colors] 处理点数: {len(labels)}\")\n",
    "        print(f\"[Rellis Colors] 输入标签范围: min={np.min(labels)}, max={np.max(labels)}\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"{'Input ID':<10} | {'Mapped Grp':<10} | {'Name':<15} | {'RGB (0-255)':<15}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # 为了不刷屏，只打印当前数据中出现的类别\n",
    "        # 如果是 Raw 模式，展示 Input -> Group -> Color\n",
    "        # 如果是 Group 模式，展示 Input(Group) -> Group -> Color\n",
    "        \n",
    "        # 限制打印数量，防止几十个类别刷屏太长，这里只打印前15个出现的唯一值示例\n",
    "        display_labels = unique_input if len(unique_input) < 20 else unique_input[:20]\n",
    "        \n",
    "        for lbl in display_labels:\n",
    "            if current_mode == 'raw':\n",
    "                grp = raw_to_group_map[lbl] if lbl < 35 else 0\n",
    "            else:\n",
    "                grp = lbl if lbl <= 8 else 0\n",
    "                \n",
    "            name = group_names.get(grp, \"Unknown\")\n",
    "            rgb = group_rgb_dict.get(grp, [0,0,0])\n",
    "            print(f\"{lbl:<10} | {grp:<10} | {name:<15} | {str(rgb):<15}\")\n",
    "            \n",
    "        if len(unique_input) > 20:\n",
    "            print(f\"... (共 {len(unique_input)} 个唯一标签，仅显示前 20 个)\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec4c971-442c-4e8f-a119-e451f52a724b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty Range: Min=nan, Max=nan\n",
      "------------------------------------------------------------\n",
      "[Rellis Colors] 检测模式: group -> 实际执行: GROUP\n",
      "[Rellis Colors] 处理点数: 17184\n",
      "[Rellis Colors] 输入标签范围: min=0, max=8\n",
      "------------------------------------------------------------\n",
      "Input ID   | Mapped Grp | Name            | RGB (0-255)    \n",
      "------------------------------------------------------------\n",
      "0          | 0          | Void            | [0, 0, 0]      \n",
      "1          | 1          | Sky             | [196, 255, 255]\n",
      "4          | 4          | Paved           | [255, 255, 0]  \n",
      "6          | 6          | Brown(Dirt)     | [153, 76, 0]   \n",
      "7          | 7          | Green(Grass)    | [111, 255, 74] \n",
      "8          | 8          | Vegetation      | [0, 102, 0]    \n",
      "------------------------------------------------------------\n",
      ">>> 正在打开窗口 1: 语义地图 (Semantics) ...\n",
      ">>> 正在打开窗口 2: 不确定性地图 (Uncertainty) ...\n"
     ]
    }
   ],
   "source": [
    "# ================= 数据导出 =================\n",
    "map_points, map_labels, map_uncs = global_map.to_pointcloud()\n",
    "\n",
    "if map_points is None:\n",
    "    print(\"错误: 地图为空\")\n",
    "else:\n",
    "    # ================= 颜色映射 (Uncertainty) =================\n",
    "    # 将 Uncertainty 0~1 映射到 颜色 (Jet/Turbo colormap)\n",
    "    import matplotlib.cm as cm\n",
    "    \n",
    "    # 归一化不确定性 (通常不确定性不会完全到0或1，可以根据分布截断)\n",
    "    print(f\"Uncertainty Range: Min={map_uncs.min():.4f}, Max={map_uncs.max():.4f}\")\n",
    "    \n",
    "    # 使用 matplotlib colormap\n",
    "    colormap = plt.get_cmap('jet') # Blue(Low Unc) -> Red(High Unc)\n",
    "    unc_colors = colormap(map_uncs)[:, :3] # 取 RGB\n",
    "    \n",
    "    # ================= 颜色映射 (Semantics) =================\n",
    "    # 复用 Step 2 的 get_rellis_colors 函数 (确保已定义)\n",
    "    # 如果 Step 2 代码在同一个 Notebook 运行过则无需重定义\n",
    "    # 这里简单做一个 fallback\n",
    "    try:\n",
    "        sem_colors = get_rellis_colors(map_labels, mode='group')\n",
    "    except NameError:\n",
    "        print(\"get_rellis_colors 未找到，使用随机颜色\")\n",
    "        sem_colors = np.random.rand(len(map_labels), 3)\n",
    "\n",
    "    # ================= Open3D 可视化 =================\n",
    "    \n",
    "    def view_pcd(points, colors, title):\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        \n",
    "        # 坐标轴\n",
    "        axis = o3d.geometry.TriangleMesh.create_coordinate_frame(size=2.0)\n",
    "        \n",
    "        o3d.visualization.draw_geometries([pcd, axis], window_name=title,\n",
    "                                          zoom=0.34,\n",
    "                                          front=[0.42, -0.21, -0.88],\n",
    "                                          lookat=[2.61, 2.04, 1.53],\n",
    "                                          up=[-0.06, -0.97, 0.20])\n",
    "\n",
    "    print(\">>> 正在打开窗口 1: 语义地图 (Semantics) ...\")\n",
    "    view_pcd(map_points, sem_colors, \"Evidential Map - Semantics\")\n",
    "    \n",
    "    print(\">>> 正在打开窗口 2: 不确定性地图 (Uncertainty) ...\")\n",
    "    # 提示: 红色代表高不确定性 (未知区域/冲突区域)，蓝色代表低不确定性\n",
    "    view_pcd(map_points, unc_colors, \"Evidential Map - Uncertainty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb099c5-22c2-41f1-b3d0-803093329331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
