{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00c34fd7-fac0-4f66-b1cf-4b1cc212f66f",
   "metadata": {},
   "source": [
    "## 1: 导入与基础配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8f0290-797e-42ec-a219-23a259ecb8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "成功导入 rellis_utils\n",
      "标定加载完毕. P: (3, 3), Poses: 2059\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================= 1. 路径设置 (复用 Step 2) =================\n",
    "# 请确保 project_root 指向包含 rellis_utils 的目录\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"Projection\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "try:\n",
    "    from rellis_utils.lidar2img import load_from_bin, get_cam_mtx, get_mtx_from_yaml\n",
    "    print(\"成功导入 rellis_utils\")\n",
    "except ImportError as e:\n",
    "    print(f\"导入失败: {e}\")\n",
    "\n",
    "# ================= 2. 数据集配置 =================\n",
    "RELLIS_ROOT = '/home/xzy/datasets/Rellis-3D'\n",
    "INFERENCE_DIR = '/home/xzy/Downloads/convertedRellis/rellisv3_edl_train-4/01_inferenced_npy'\n",
    "SEQ_ID = '00004'\n",
    "\n",
    "# 处理帧数范围\n",
    "START_FRAME_IDX = 0\n",
    "NUM_FRAMES = 10        # 建议跑 100-200 帧以观察融合效果\n",
    "VOXEL_SIZE = 0.2        # 体素分辨率 (单位: 米)，越小越精细但内存消耗越大\n",
    "\n",
    "# 图像与投影参数\n",
    "PROJ_SHAPE = (1200, 1920) \n",
    "MAP_SHAPE = (600, 960)    \n",
    "dist_coeff = np.array([-0.134313,-0.025905,0.002181,0.00084,0]).reshape((5,1))\n",
    "\n",
    "# ================= 3. 加载标定与位姿 =================\n",
    "# 相机参数\n",
    "cam_info_path = os.path.join(RELLIS_ROOT, 'Rellis_3D_cam_intrinsic', 'Rellis-3D', SEQ_ID, 'camera_info.txt')\n",
    "if not os.path.exists(cam_info_path): cam_info_path = os.path.join(RELLIS_ROOT, SEQ_ID, 'camera_info.txt')\n",
    "trans_path = os.path.join(RELLIS_ROOT, SEQ_ID, 'transforms.yaml')\n",
    "poses_file = os.path.join(RELLIS_ROOT, SEQ_ID, 'poses.txt')\n",
    "\n",
    "P = get_cam_mtx(cam_info_path)\n",
    "RT_os1_to_cam = get_mtx_from_yaml(trans_path)\n",
    "\n",
    "def load_poses(pose_file):\n",
    "    poses = []\n",
    "    with open(pose_file, 'r') as f:\n",
    "        for line in f:\n",
    "            mat = np.eye(4)\n",
    "            mat[:3, :] = np.fromstring(line, sep=' ').reshape(3, 4)\n",
    "            poses.append(mat)\n",
    "    return poses\n",
    "\n",
    "all_poses = load_poses(poses_file)\n",
    "print(f\"标定加载完毕. P: {P.shape}, Poses: {len(all_poses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6613c00-21ed-465e-a279-20b4f2569db5",
   "metadata": {},
   "source": [
    "## 2. 核心数学工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a319466-cd42-4bc7-aa10-ef789794af4b",
   "metadata": {},
   "source": [
    "### 证据理论 (Evidential Theory) 形式化定义\n",
    "\n",
    "#### 1. 从 Dirichlet 分布到 Mass (Belief)\n",
    "基于主观逻辑（Subjective Logic）与证据深度学习（Evidential Deep Learning, EDL）框架，对于 $K$ 个类别的分类问题，Dirichlet 分布的参数 $\\boldsymbol{\\alpha} = [\\alpha_1, \\dots, \\alpha_K]$ 与 Dempster-Shafer 证据理论中的 Mass（或称 Belief）$b_k$ 及不确定性 $u$ 的映射关系定义如下：\n",
    "\n",
    "$$\n",
    "S = \\sum_{k=1}^{K} \\alpha_k\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_k = \\frac{\\alpha_k - 1}{S}, \\quad \\forall k \\in \\{1, \\dots, K\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "u = \\frac{K}{S}\n",
    "$$\n",
    "\n",
    "其中，需满足约束 $\\sum_{k=1}^{K} b_k + u = 1$ 且 $\\alpha_k \\ge 1$。\n",
    "\n",
    "#### 2. Dempster 组合规则 (Dempster's Rule of Combination)\n",
    "给定两个独立的证据来源（例如两个不同视角的观测或时序上的前后帧），分别由 $( \\mathbf{b}^{(1)}, u^{(1)} )$ 和 $( \\mathbf{b}^{(2)}, u^{(2)} )$ 表示。利用 Dempster 组合规则进行融合，得到新的联合置信度。\n",
    "\n",
    "首先计算**冲突因子 (Conflict Factor)** $C$，表示两个证据之间相互矛盾的程度：\n",
    "\n",
    "$$\n",
    "C = \\sum_{i \\neq j} b_i^{(1)} b_j^{(2)}\n",
    "$$\n",
    "\n",
    "融合后的 Mass $b_k^{new}$ 和 Uncertainty $u^{new}$ 计算如下：\n",
    "\n",
    "$$\n",
    "b_k^{new} = \\frac{1}{1-C} \\left( b_k^{(1)} b_k^{(2)} + b_k^{(1)} u^{(2)} + b_k^{(2)} u^{(1)} \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "u^{new} = \\frac{1}{1-C} \\left( u^{(1)} u^{(2)} \\right)\n",
    "$$\n",
    "\n",
    "该规则有效地利用了不确定性信息：当一方非常确信（$u$ 很小）而另一方不确定（$u$ 很大）时，融合结果将偏向确信的一方。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d4e9c3-fc1c-4d1f-b368-3efc3620ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= 证据理论 (Evidential Theory) 核心函数 =================\n",
    "\n",
    "def alpha_to_mass(alpha):\n",
    "    \"\"\"\n",
    "    将 Dirichlet 参数 alpha 转换为 DS Mass 和 Uncertainty\n",
    "    Input: alpha (..., K)\n",
    "    Output: mass (..., K), uncertainty (..., 1)\n",
    "\n",
    "    对于 K 个类别的分类问题：\n",
    "    alpha: Dirichlet 分布的参数\n",
    "    mass: 证据理论中的 Mass（或称 Belief, b）\n",
    "    u:    证据理论中的 不确定性\n",
    "    \"\"\"\n",
    "    # 确保 alpha >= 1.0 (防止数值下溢)\n",
    "    alpha = np.maximum(alpha, 1.0001)\n",
    "    \n",
    "    S = np.sum(alpha, axis=-1, keepdims=True) # S = sum(alpha)\n",
    "    K = alpha.shape[-1]\n",
    "    \n",
    "    # Belief/Mass k = (alpha_k - 1) / S\n",
    "    mass = (alpha - 1.0) / S\n",
    "    \n",
    "    # Uncertainty = K / S\n",
    "    uncertainty = K / S\n",
    "    \n",
    "    # 数值截断：确保 mass 和 uncertainty 在 [0, 1] 之间，且和为 1\n",
    "    # 虽然理论上公式保证了这一点，但浮点误差可能导致溢出\n",
    "    mass = np.clip(mass, 0.0, 1.0)\n",
    "    uncertainty = np.clip(uncertainty, 0.0, 1.0)\n",
    "    \n",
    "    return mass, uncertainty\n",
    "\n",
    "def dempster_fusion_numpy(m1, m2, u1, u2):\n",
    "    \"\"\"\n",
    "    DS 组合规则 (Vectorized Numpy Version)\n",
    "    融合两个 Mass 分布 m1 (old), m2 (new observation)\n",
    "\n",
    "    m: Dempster-Shafer 证据理论中的 Mass（或称 Belief）b\n",
    "    u: Dempster-Shafer 证据理论中的 不确定性 \n",
    "    \"\"\"\n",
    "    # 维度检查与广播处理\n",
    "    if m1.ndim == 1: m1 = m1[None, :]\n",
    "    if m2.ndim == 1: m2 = m2[None, :]\n",
    "    if np.isscalar(u1): u1 = np.array([u1])\n",
    "    if np.isscalar(u2): u2 = np.array([u2])\n",
    "    \n",
    "    if u1.ndim == 0: u1 = u1[None] # Handle scalar array\n",
    "    if u2.ndim == 0: u2 = u2[None]\n",
    "    # 确保 u1, u2 维度为 (Batch, 1) 以便广播\n",
    "    if u1.ndim == 1: u1 = u1[:, None]\n",
    "    if u2.ndim == 1: u2 = u2[:, None]\n",
    "\n",
    "    \n",
    "    # --- 1. 计算冲突因子 C (优化版) ---\n",
    "    # 原逻辑：Sum(OuterProduct) - Sum(Diagonal)\n",
    "    # 优化逻辑：Sum(m1) * Sum(m2) - Sum(m1 * m2)\n",
    "    # 这种方式避免了构建巨大的 [Batch, K, K] 矩阵，速度更快，内存更省\n",
    "    \n",
    "    sum_m1 = np.sum(m1, axis=-1, keepdims=True)\n",
    "    sum_m2 = np.sum(m2, axis=-1, keepdims=True)\n",
    "    \n",
    "    # 两个证据支持同一类的部分 (Diagonal term)\n",
    "    consensus = m1 * m2\n",
    "    sum_diag = np.sum(consensus, axis=-1, keepdims=True)\n",
    "    \n",
    "    # 所有可能的组合 (包括冲突和共识)\n",
    "    sum_all = sum_m1 * sum_m2\n",
    "    \n",
    "    # 冲突因子 C\n",
    "    C = sum_all - sum_diag\n",
    "        \n",
    "    # --- 2. 归一化因子 (数值稳定处理) ---\n",
    "    norm_factor = 1.0 - C\n",
    "    \n",
    "    # 防止除零和极小分母\n",
    "    # 这里的 epsilon 可以稍微大一点，或者使用 soft clipping\n",
    "    EPS = 1e-6\n",
    "    norm_factor = np.clip(norm_factor, EPS, None) \n",
    "    \n",
    "    # --- 3. 融合 Mass ---\n",
    "    # 公式：m_new = (m1*m2 + m1*u2 + m2*u1) / (1-C)\n",
    "    term1 = consensus           # m1[i] * m2[i]\n",
    "    term2 = m1 * u2             # m1[i] * u2 (广播)\n",
    "    term3 = m2 * u1             # m2[i] * u1 (广播)\n",
    "    \n",
    "    m_new = (term1 + term2 + term3) / norm_factor\n",
    "    \n",
    "    # --- 4. 融合 Uncertainty ---\n",
    "    # 公式：u_new = (u1*u2) / (1-C)\n",
    "    u_new = (u1 * u2) / norm_factor\n",
    "    \n",
    "    # --- 5. 最后的数值安全检查 ---\n",
    "    # 极端冲突下，结果可能溢出或 NaN，这里做兜底\n",
    "    # 替换 NaN 为 0，Inf 为 1 (或者均匀分布)\n",
    "    if np.any(np.isnan(m_new)) or np.any(np.isinf(m_new)):\n",
    "        # print(\"Warning: NaN/Inf detected in DS fusion. Resetting to uncertainty.\")\n",
    "        m_new = np.nan_to_num(m_new, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "        u_new = np.nan_to_num(u_new, nan=1.0, posinf=1.0, neginf=1.0)\n",
    "\n",
    "    # 再次截断，防止浮点漂移导致 >1\n",
    "    m_new = np.clip(m_new, 0.0, 1.0)\n",
    "    u_new = np.clip(u_new, 0.0, 1.0)\n",
    "\n",
    "    # --- 6. 最终严格归一化 (Optional but Recommended) ---\n",
    "    # 因为前面的 clipping 可能破坏了 sum(m) + u = 1 的约束\n",
    "    # 重新计算 total 并在最后一维进行除法\n",
    "    total = np.sum(m_new, axis=-1, keepdims=True) + u_new\n",
    "    \n",
    "    # 再次防止 total 为 0 (虽然极不可能，但为了绝对安全)\n",
    "    total = np.maximum(total, 1e-9)\n",
    "    \n",
    "    m_new = m_new / total\n",
    "    u_new = u_new / total\n",
    "    \n",
    "    return m_new, u_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735acedc-f06b-4581-8e30-2cee5405e238",
   "metadata": {},
   "source": [
    "## 3. Voxel Map 类定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3618c1c6-c781-4aa6-8dcc-86bd0f130e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel Map 类定义完成。\n"
     ]
    }
   ],
   "source": [
    "class EvidentialVoxelMap:\n",
    "    def __init__(self, resolution=0.2, num_classes=9):\n",
    "        self.resolution = resolution\n",
    "        self.num_classes = num_classes\n",
    "        # 稀疏地图: Key=(x,y,z), Value={'mass': np.array, 'unc': float, 'count': int}\n",
    "        self.voxels = {} \n",
    "\n",
    "    def update(self, points, alphas):\n",
    "        \"\"\"\n",
    "        更新地图状态\n",
    "        points: (N, 3) 世界坐标系下的点\n",
    "        alphas: (N, K) 对应的 Dirichlet 参数\n",
    "        \"\"\"\n",
    "        # 1. 转换观测值为 Mass/Uncertainty\n",
    "        obs_masses, obs_uncs = alpha_to_mass(alphas)\n",
    "        \n",
    "        # 2. 计算体素索引\n",
    "        voxel_indices = np.floor(points / self.resolution).astype(int)\n",
    "        \n",
    "        # 3. 逐点融合 (这里使用简单的 Python 循环，后续可用 C++ 绑定或 Numba 优化)\n",
    "        # 为了加速，我们先在当前帧内部进行聚合（处理同一帧落入同一体素的点）\n",
    "        \n",
    "        # 构建当前帧的临时字典: idx -> list of indices\n",
    "        unique_indices, inv_inds = np.unique(voxel_indices, axis=0, return_inverse=True)\n",
    "        \n",
    "        # 遍历当前帧涉及的每一个体素\n",
    "        for i, idx_arr in enumerate(unique_indices):\n",
    "            idx_tuple = tuple(idx_arr)\n",
    "            \n",
    "            # 找到当前帧所有属于该体素的点\n",
    "            mask = (inv_inds == i)\n",
    "            \n",
    "            # === 策略 A: 帧内取平均 (简单且有效) ===\n",
    "            # 同一帧内打到同一个体素的点，通常视为一次观测，取 alpha 的均值作为本次观测\n",
    "            # (也可以取 Max，或者视为多次观测连续融合)\n",
    "            avg_mass = np.mean(obs_masses[mask], axis=0)\n",
    "            avg_unc = np.mean(obs_uncs[mask])\n",
    "            \n",
    "            if idx_tuple not in self.voxels:\n",
    "                # 初始化\n",
    "                self.voxels[idx_tuple] = {\n",
    "                    'mass': avg_mass,\n",
    "                    'uncertainty': avg_unc,\n",
    "                    'count': 1\n",
    "                }\n",
    "            else:\n",
    "                # 融合 (Temporal Fusion)\n",
    "                old_data = self.voxels[idx_tuple]\n",
    "                \n",
    "                new_m, new_u = dempster_fusion_numpy(\n",
    "                    old_data['mass'], avg_mass, \n",
    "                    old_data['uncertainty'], avg_unc\n",
    "                )\n",
    "\n",
    "                \n",
    "                # 更新状态\n",
    "                self.voxels[idx_tuple]['mass'] = new_m.flatten()          # (1, K) -> (K,)\n",
    "                self.voxels[idx_tuple]['uncertainty'] = new_u[0][0]       # (1, 1) -> (,)\n",
    "                self.voxels[idx_tuple]['count'] += 1\n",
    "\n",
    "    def to_pointcloud(self):\n",
    "        \"\"\"将体素地图导出为 numpy 数组用于可视化\"\"\"\n",
    "        if not self.voxels:\n",
    "            return None, None, None\n",
    "            \n",
    "        pts = []\n",
    "        labels = []\n",
    "        uncs = []\n",
    "        \n",
    "        for idx, data in self.voxels.items():\n",
    "            # 恢复中心坐标\n",
    "            pt = (np.array(idx) * self.resolution) + (self.resolution / 2.0)\n",
    "            pts.append(pt)\n",
    "            \n",
    "            # 获取最大概率类别\n",
    "            label = np.argmax(data['mass'])\n",
    "            labels.append(label)\n",
    "            \n",
    "            # 获取不确定性\n",
    "            uncs.append(data['uncertainty'])\n",
    "            \n",
    "        return np.array(pts), np.array(labels), np.array(uncs)\n",
    "\n",
    "    def prune(self, min_count=2):\n",
    "        \"\"\"(可选) 清除只观测到一两次的噪声体素\"\"\"\n",
    "        keys_to_remove = [k for k, v in self.voxels.items() if v['count'] < min_count]\n",
    "        for k in keys_to_remove:\n",
    "            del self.voxels[k]\n",
    "        print(f\"已修剪 {len(keys_to_remove)} 个噪声体素\")\n",
    "\n",
    "print(\"Voxel Map 类定义完成。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf797ff4-2c10-4498-8a6b-f8633c501e86",
   "metadata": {},
   "source": [
    "## 4. 主循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a272e8d-7d92-4ccf-8e6e-15c35b7e7afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始 Evidential Mapping (Frames 0 - 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已修剪 1039 个噪声体素\n",
      "建图完成! 总体素数量: 3054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================= 辅助投影函数 (复用 Step 2) =================\n",
    "def project_and_get_data(lidar_file, npy_file, P, RT, img_size, map_shape):\n",
    "    \"\"\"\n",
    "    return:\n",
    "        final_points: 原始点云数据，但是过滤只保留了可以在图像上找到对应点的\n",
    "        point_alphas: 图像语义概率，有一个形状的转换\n",
    "    \"\"\"\n",
    "    # 加载数据\n",
    "    points = load_from_bin(lidar_file)\n",
    "    prob_map = np.load(npy_file) # 这是 alpha map (H_map, W_map, K)\n",
    "    \n",
    "    # 投影\n",
    "    h, w = img_size\n",
    "    xyz_h = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    xyz_cam = (RT @ xyz_h.T).T[:, :3]\n",
    "    \n",
    "    # Z轴过滤\n",
    "    mask_z = xyz_cam[:, 2] > 3.0 \n",
    "    xyz_cam = xyz_cam[mask_z]\n",
    "    points = points[mask_z]\n",
    "    \n",
    "    # cv2 投影\n",
    "    img_points, _ = cv2.projectPoints(xyz_cam, np.zeros(3), np.zeros(3), P, dist_coeff)\n",
    "    img_points = img_points.squeeze()\n",
    "    \n",
    "    # 图像范围过滤\n",
    "    u, v = img_points[:, 0], img_points[:, 1]\n",
    "    mask_uv = (u >= 0) & (u < w) & (v >= 0) & (v < h)\n",
    "    \n",
    "    final_u = u[mask_uv]\n",
    "    final_v = v[mask_uv]\n",
    "    final_points = points[mask_uv] # Local LiDAR Frame\n",
    "    \n",
    "    # 采样 .npy (Alpha)\n",
    "    # 注意 map_shape 和 img_shape 的比例\n",
    "    scale_x = map_shape[1] / w\n",
    "    scale_y = map_shape[0] / h\n",
    "    \n",
    "    u_map = np.clip((final_u * scale_x).astype(int), 0, map_shape[1]-1)\n",
    "    v_map = np.clip((final_v * scale_y).astype(int), 0, map_shape[0]-1)\n",
    "    \n",
    "    # 获取每个点的 alpha 向量 (N, K)\n",
    "    # 注意 prob_map 形状通常是 (H, W, K) 或 (K, H, W)，请根据实际情况调整 transpose\n",
    "    # 假设 prob_map 是 (K, H, W)，如 Step 2 所述\n",
    "    if prob_map.shape[0] == 9: # Channels first\n",
    "        point_alphas = prob_map[:, v_map, u_map].T \n",
    "    else: # Channels last\n",
    "        point_alphas = prob_map[v_map, u_map, :]\n",
    "        \n",
    "    return final_points, point_alphas\n",
    "\n",
    "# ================= 主执行流程 =================\n",
    "\n",
    "# 1. 初始化地图\n",
    "global_map = EvidentialVoxelMap(resolution=VOXEL_SIZE, num_classes=9)\n",
    "\n",
    "print(f\"开始 Evidential Mapping (Frames {START_FRAME_IDX} - {START_FRAME_IDX + NUM_FRAMES})...\")\n",
    "\n",
    "for i in tqdm(range(START_FRAME_IDX, START_FRAME_IDX + NUM_FRAMES)):\n",
    "    frame_str = f\"{i:06d}\"\n",
    "    \n",
    "    # 构建路径\n",
    "    lidar_path = os.path.join(RELLIS_ROOT, SEQ_ID, 'os1_cloud_node_kitti_bin', f\"{frame_str}.bin\")\n",
    "    npy_pattern = os.path.join(INFERENCE_DIR, SEQ_ID, f\"frame{frame_str}-*.npy\")\n",
    "    npy_matches = glob.glob(npy_pattern)\n",
    "    \n",
    "    if not os.path.exists(lidar_path) or not npy_matches:\n",
    "        continue\n",
    "        \n",
    "    # 1. 获取单帧数据 (Local Frame)\n",
    "    pts_local, alphas = project_and_get_data(\n",
    "        lidar_path, npy_matches[0], P, RT_os1_to_cam, PROJ_SHAPE, MAP_SHAPE\n",
    "    )\n",
    "    \n",
    "    if len(pts_local) == 0: continue\n",
    "    \n",
    "    # 2. 转到世界坐标系 (World Frame)\n",
    "    T_curr = all_poses[i]\n",
    "    pts_homo = np.hstack((pts_local, np.ones((pts_local.shape[0], 1))))\n",
    "    pts_world = (T_curr @ pts_homo.T).T[:, :3]\n",
    "    \n",
    "    # 3. 更新体素地图\n",
    "    global_map.update(pts_world, alphas)\n",
    "\n",
    "# (可选) 修剪噪声\n",
    "global_map.prune(min_count=2)\n",
    "\n",
    "print(f\"建图完成! 总体素数量: {len(global_map.voxels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d25ca-0b4b-4774-af71-c68bfd2c2a47",
   "metadata": {},
   "source": [
    "## 5. 可视化 (不确定性与语义)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f41a87bf-aa60-475e-92a8-27fbaf429e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_rellis_colors(labels, mode='auto', verbose=True):\n",
    "    \"\"\"\n",
    "    获取 Rellis-3D 的颜色映射，支持原始标签(Raw)和归类标签(Group)。\n",
    "    \n",
    "    参数:\n",
    "        labels: (N,) 的整数数组/列表\n",
    "        mode: \n",
    "            'auto': 自动判断。如果 max(label) > 8 则认为是 'raw'，否则认为是 'group'。\n",
    "            'raw':  强制认为是原始 ID (0-34)。\n",
    "            'group': 强制认为是归类 ID (0-8)。\n",
    "        verbose: 是否打印详细的映射信息 (True/False)。\n",
    "        \n",
    "    输出:\n",
    "        colors: (N, 3) 的 float 数组 (0.0-1.0)\n",
    "    \"\"\"\n",
    "    labels = np.array(labels, dtype=int)\n",
    "    if labels.size == 0:\n",
    "        return np.zeros((0, 3))\n",
    "\n",
    "    # ================= Data Definition =================\n",
    "    # 1. Raw ID (0-34) -> Group ID (0-8)\n",
    "    # 索引为 Raw ID，值为 Group ID\n",
    "    raw_to_group_map = np.zeros(35, dtype=int)\n",
    "    mapping_data = {\n",
    "        0:0, 1:6, 2:5, 3:7, 4:8, 5:3, 6:2, 7:1, 8:3, 9:3, \n",
    "        10:4, 11:5, 12:3, 13:6, 14:5, 15:6, 16:3, 17:3, 18:0, \n",
    "        19:8, 20:3, 21:0, 22:3, 23:4, 24:3, 27:0, 31:2, 33:6, 34:0\n",
    "    }\n",
    "    for k, v in mapping_data.items():\n",
    "        if k < 35: raw_to_group_map[k] = v\n",
    "\n",
    "    # 2. Group ID (0-8) -> RGB (0-255)\n",
    "    group_rgb_dict = {\n",
    "        0: [0, 0, 0],       # void\n",
    "        1: [196, 255, 255], # sky\n",
    "        2: [0, 0, 255],     # water\n",
    "        3: [204, 153, 255], # object (pole, barrier, etc)\n",
    "        4: [255, 255, 0],   # paved (asphalt, concrete)\n",
    "        5: [255, 153, 204], # unpaved (mud, rubble)\n",
    "        6: [153, 76, 0],    # brown (dirt, mulch)\n",
    "        7: [111, 255, 74],  # green (grass)\n",
    "        8: [0, 102, 0]      # vegetation (tree, bush)\n",
    "    }\n",
    "    \n",
    "    # 3. Group ID -> Name (for logging)\n",
    "    group_names = {\n",
    "        0: \"Void\", 1: \"Sky\", 2: \"Water\", 3: \"Object\", 4: \"Paved\", \n",
    "        5: \"Unpaved\", 6: \"Brown(Dirt)\", 7: \"Green(Grass)\", 8: \"Vegetation\"\n",
    "    }\n",
    "\n",
    "    # ================= Mode Selection =================\n",
    "    max_val = np.max(labels)\n",
    "    \n",
    "    if mode == 'auto':\n",
    "        # 启发式判断：如果存在大于8的标签，一定是Raw；\n",
    "        # 如果全都在0-8之间，优先假设是Group (因为通常可视化时如果是Raw，很难完全避开>8的ID)\n",
    "        if max_val > 8:\n",
    "            current_mode = 'raw'\n",
    "        else:\n",
    "            current_mode = 'group'\n",
    "    else:\n",
    "        current_mode = mode\n",
    "\n",
    "    # ================= Mapping Execution =================\n",
    "    \n",
    "    # 最终用于查颜色的索引 (Group IDs)\n",
    "    target_groups = None \n",
    "\n",
    "    if current_mode == 'raw':\n",
    "        # 越界处理：超过34的全部设为0 (Void)\n",
    "        safe_labels = labels.copy()\n",
    "        safe_labels[safe_labels >= 35] = 0\n",
    "        target_groups = raw_to_group_map[safe_labels]\n",
    "    else: # mode == 'group'\n",
    "        # 越界处理：超过8的全部设为0 (Void)\n",
    "        target_groups = labels.copy()\n",
    "        target_groups[target_groups > 8] = 0\n",
    "    \n",
    "    # 映射颜色\n",
    "    # 先构建一个 (9, 3) 的颜色查找表数组\n",
    "    color_lookup = np.zeros((9, 3))\n",
    "    for i in range(9):\n",
    "        color_lookup[i] = group_rgb_dict[i]\n",
    "    \n",
    "    # 归一化到 0-1\n",
    "    color_lookup_norm = color_lookup / 255.0\n",
    "    \n",
    "    # 获取最终颜色\n",
    "    colors = color_lookup_norm[target_groups]\n",
    "\n",
    "    # ================= INFO Logging =================\n",
    "    if verbose:\n",
    "        unique_input = np.unique(labels)\n",
    "        unique_groups = np.unique(target_groups)\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "        print(f\"[Rellis Colors] 检测模式: {mode} -> 实际执行: {current_mode.upper()}\")\n",
    "        print(f\"[Rellis Colors] 处理点数: {len(labels)}\")\n",
    "        print(f\"[Rellis Colors] 输入标签范围: min={np.min(labels)}, max={np.max(labels)}\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"{'Input ID':<10} | {'Mapped Grp':<10} | {'Name':<15} | {'RGB (0-255)':<15}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # 为了不刷屏，只打印当前数据中出现的类别\n",
    "        # 如果是 Raw 模式，展示 Input -> Group -> Color\n",
    "        # 如果是 Group 模式，展示 Input(Group) -> Group -> Color\n",
    "        \n",
    "        # 限制打印数量，防止几十个类别刷屏太长，这里只打印前15个出现的唯一值示例\n",
    "        display_labels = unique_input if len(unique_input) < 20 else unique_input[:20]\n",
    "        \n",
    "        for lbl in display_labels:\n",
    "            if current_mode == 'raw':\n",
    "                grp = raw_to_group_map[lbl] if lbl < 35 else 0\n",
    "            else:\n",
    "                grp = lbl if lbl <= 8 else 0\n",
    "                \n",
    "            name = group_names.get(grp, \"Unknown\")\n",
    "            rgb = group_rgb_dict.get(grp, [0,0,0])\n",
    "            print(f\"{lbl:<10} | {grp:<10} | {name:<15} | {str(rgb):<15}\")\n",
    "            \n",
    "        if len(unique_input) > 20:\n",
    "            print(f\"... (共 {len(unique_input)} 个唯一标签，仅显示前 20 个)\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aec4c971-442c-4e8f-a119-e451f52a724b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty Range: Min=0.0000, Max=0.4827\n",
      "------------------------------------------------------------\n",
      "[Rellis Colors] 检测模式: group -> 实际执行: GROUP\n",
      "[Rellis Colors] 处理点数: 3054\n",
      "[Rellis Colors] 输入标签范围: min=0, max=8\n",
      "------------------------------------------------------------\n",
      "Input ID   | Mapped Grp | Name            | RGB (0-255)    \n",
      "------------------------------------------------------------\n",
      "0          | 0          | Void            | [0, 0, 0]      \n",
      "1          | 1          | Sky             | [196, 255, 255]\n",
      "4          | 4          | Paved           | [255, 255, 0]  \n",
      "6          | 6          | Brown(Dirt)     | [153, 76, 0]   \n",
      "7          | 7          | Green(Grass)    | [111, 255, 74] \n",
      "8          | 8          | Vegetation      | [0, 102, 0]    \n",
      "------------------------------------------------------------\n",
      ">>> 正在打开窗口 1: 语义地图 (Semantics) ...\n",
      ">>> 正在打开窗口 2: 不确定性地图 (Uncertainty) ...\n"
     ]
    }
   ],
   "source": [
    "# ================= 数据导出 =================\n",
    "map_points, map_labels, map_uncs = global_map.to_pointcloud()\n",
    "\n",
    "if map_points is None:\n",
    "    print(\"错误: 地图为空\")\n",
    "else:\n",
    "    # ================= 颜色映射 (Uncertainty) =================\n",
    "    # 将 Uncertainty 0~1 映射到 颜色 (Jet/Turbo colormap)\n",
    "    import matplotlib.cm as cm\n",
    "    \n",
    "    # 归一化不确定性 (通常不确定性不会完全到0或1，可以根据分布截断)\n",
    "    print(f\"Uncertainty Range: Min={map_uncs.min():.4f}, Max={map_uncs.max():.4f}\")\n",
    "    \n",
    "    # 使用 matplotlib colormap\n",
    "    colormap = plt.get_cmap('jet') # Blue(Low Unc) -> Red(High Unc)\n",
    "    unc_colors = colormap(map_uncs)[:, :3] # 取 RGB\n",
    "    \n",
    "    # ================= 颜色映射 (Semantics) =================\n",
    "    # 复用 Step 2 的 get_rellis_colors 函数 (确保已定义)\n",
    "    # 如果 Step 2 代码在同一个 Notebook 运行过则无需重定义\n",
    "    # 这里简单做一个 fallback\n",
    "    try:\n",
    "        sem_colors = get_rellis_colors(map_labels, mode='group')\n",
    "    except NameError:\n",
    "        print(\"get_rellis_colors 未找到，使用随机颜色\")\n",
    "        sem_colors = np.random.rand(len(map_labels), 3)\n",
    "\n",
    "    # ================= Open3D 可视化 =================\n",
    "    \n",
    "    def view_pcd(points, colors, title):\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        \n",
    "        # 坐标轴\n",
    "        axis = o3d.geometry.TriangleMesh.create_coordinate_frame(size=2.0)\n",
    "        \n",
    "        o3d.visualization.draw_geometries([pcd, axis], window_name=title,\n",
    "                                          zoom=0.34,\n",
    "                                          front=[0.42, -0.21, -0.88],\n",
    "                                          lookat=[2.61, 2.04, 1.53],\n",
    "                                          up=[-0.06, -0.97, 0.20])\n",
    "\n",
    "    print(\">>> 正在打开窗口 1: 语义地图 (Semantics) ...\")\n",
    "    view_pcd(map_points, sem_colors, \"Evidential Map - Semantics\")\n",
    "    \n",
    "    print(\">>> 正在打开窗口 2: 不确定性地图 (Uncertainty) ...\")\n",
    "    # 提示: 红色代表高不确定性 (未知区域/冲突区域)，蓝色代表低不确定性\n",
    "    view_pcd(map_points, unc_colors, \"Evidential Map - Uncertainty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb099c5-22c2-41f1-b3d0-803093329331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
